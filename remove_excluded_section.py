"""
ê°œë³„ HTML ë³´ê³ ì„œì—ì„œ "ì´ë¯¸ ë¶„ì„ ì™„ë£Œëœ ê¸°ì—…" ì„¹ì…˜ ì œê±°
"""
import os
from bs4 import BeautifulSoup

html_dir = os.path.dirname(os.path.abspath(__file__))
html_files = [f for f in os.listdir(html_dir) if f.endswith('.html') and f != 'index.html']

print('ğŸ§¹ ê°œë³„ HTML ë³´ê³ ì„œì—ì„œ ì œì™¸ ê¸°ì—… ì„¹ì…˜ ì œê±° ì¤‘...\n')

for html_file in html_files:
    file_path = os.path.join(html_dir, html_file)

    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
        soup = BeautifulSoup(content, 'html.parser')

    removed = False

    # ë‹¤ì–‘í•œ íŒ¨í„´ìœ¼ë¡œ ì œì™¸ ê¸°ì—… ì„¹ì…˜ ì°¾ê¸°
    # 1. "ì œì™¸ëœ ê¸°ì—…" ë˜ëŠ” "ì´ë¯¸ ë¶„ì„ ì™„ë£Œëœ ê¸°ì—…" ì œëª©ì„ ê°€ì§„ ì„¹ì…˜
    for heading in soup.find_all(['h2', 'h3', 'div']):
        text = heading.get_text(strip=True)
        if any(keyword in text for keyword in ['ì œì™¸', 'ë¶„ì„ ì™„ë£Œ', 'ì´ë¯¸ ë¶„ì„', 'Excluded', 'ì œì™¸ ê¸°ì—…']):
            # í•´ë‹¹ ì„¹ì…˜ ì „ì²´ ì œê±° (ë‹¤ìŒ h2ê¹Œì§€ ë˜ëŠ” ë¶€ëª¨ div)
            parent = heading.find_parent('div', class_='section')
            if parent:
                parent.decompose()
                removed = True
                print(f'   âœ… {html_file}: ì„¹ì…˜ ì œê±° ì™„ë£Œ')
                break
            else:
                # sectionì´ ì—†ìœ¼ë©´ headingë¶€í„° ë‹¤ìŒ h2 ì „ê¹Œì§€ ì œê±°
                next_sibling = heading.find_next_sibling()
                heading.decompose()
                while next_sibling and next_sibling.name not in ['h2', 'h3']:
                    temp = next_sibling.find_next_sibling()
                    next_sibling.decompose()
                    next_sibling = temp
                removed = True
                print(f'   âœ… {html_file}: í…ìŠ¤íŠ¸ ì œê±° ì™„ë£Œ')
                break

    if removed:
        # íŒŒì¼ ì €ì¥
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(str(soup))
    else:
        print(f'   â„¹ï¸  {html_file}: ì œì™¸ ì„¹ì…˜ ì—†ìŒ')

print('\nâœ… ëª¨ë“  HTML íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!')
